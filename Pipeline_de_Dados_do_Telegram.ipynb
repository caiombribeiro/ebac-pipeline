{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline de Dados do Telegram**"
      ],
      "metadata": {
        "id": "EHqFGhBiiry-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tópicos**\n",
        "\n",
        "\n",
        "0. Contexto\n",
        "1. Arquitetura;\n",
        "2. Análise exploratória de dados;\n",
        "3. Resultado.\n"
      ],
      "metadata": {
        "id": "etM6S0RfipM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **0\\. Contexto**"
      ],
      "metadata": {
        "id": "jQ9gfgDvi5Da"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/Caiombr/ebac-pipeline/main/images-notebook/chatbot.jpg\" width=\"280\" />\n",
        "\n",
        "<font size=\"1\"><a href=\"http://www.freepik.com\">Designed by stories / Freepik</a></font>"
      ],
      "metadata": {
        "id": "UpMTnNR4z2qj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Todos nós temos contato com o mundo digital e suas facilidades. Uma dessas tecnologias que chegaram para ficar são os chatbots, sistemas de interação automática de mensagens. Normalmente, o chatbot ajuda a direcionar o cliente para um atendimento mais dinâmico, diminuindo a necessidade do atendente humano.\n",
        "\n",
        "Porém, ele também pode ser um aliado em compreensão das solicitações do cliente por meio da coleta de dados. Pense comigo: se a empresa souber qual o tipo de atendimento mais solicitado, qual a duvida mais recorrente? Qual os problemas que as pessoas mais enfrentam entre outras possibilidades? Etc.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NlkrZ3N5rJ5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "W4HMyc4Dx6_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Caiombr/ebac-pipeline/main/images-notebook/dados.png\" width=\"300\" />"
      ],
      "metadata": {
        "id": "XRTlM2Dr9BNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Contudo, não adianta só ter o bot e coletar os dados. Primeiro, acontece essa coleta das informações por meio do chatbot no grupo, processo esse que ocorrerá de forma autônoma pelas API's do telegram e da AWS.\n",
        "\n",
        "Depois, tem que haver toda uma segmentação analítica desses dados, fazendo toda a manipulação de forma que possamos ler, estruturar em conjuntos bem definidos para posterior análise em visualização.\n",
        "\n",
        "Tendo em vista dos dados trabalhados, é possivel tanto gerar insights das mensagens circuladas no grupo em formato de tabela estruturada, quando gerar gráficos em dashboards e visualização.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j1Q0V8Sxww0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "W0YLvYyNyDfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com isso, esse trabalho tem como objetivo utilizar um chatbot para coletar os dados presentes em um grupo do Telegram por meio das etapas de ingestão, ETL e Apresentação. Para isso, serão utilizados os serviços da AWS.\n",
        "\n",
        "O resumo está presente na imagem:\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/Caiombr/ebac-pipeline/blob/main/images-notebook/arquitetura.png?raw=true\" />"
      ],
      "metadata": {
        "id": "Kw_cMNDWr51O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **1\\. Arquitetura**"
      ],
      "metadata": {
        "id": "QDnGvyRRjeVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### **1\\.1. Sistema transacional**"
      ],
      "metadata": {
        "id": "z66khjXqvSEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/Caiombr/ebac-pipeline/main/images-notebook/botfather.jpg\" width=\"150\"/>"
      ],
      "metadata": {
        "id": "x8O4p3Cp8vTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O sistema utilizado aqui será o **Telegram**, uma plataforma de mensagens instantâneas *freeware* (distribuído gratuitamente) e, em sua maioria, *open source*. Ele possui um sistema de bot de fácil criação por meio do BotFather. Por meio do Bot criado em um grupo do Telegram, será utilizada a API do Telegram, para que todas as mensagens enviadas no grupo possam ser arquivadas como JSON.  \n",
        "\n",
        "É possivel coletar informações diversas por meio do JSON, como conteúdo da mensagem, remetente, dia de envio etc., redirecionado via *webhook* do *backend* do aplicativo para um *endpoint* (endereço *web* que aceita requisições HTTP) exposto pelo `AWS API Gateway`, utilizando o `AWS lambda` com o código Python nesse [link](https://github.com/Caiombr/ebac-pipeline/blob/main/ebac-caiombr-datalake-raw.py) e salvando tudo em um bucket no `AWS S3`.\n",
        "\n",
        "Também houve a padronização das permissões no `AWS IAM`, mas foram todas informadas como full access ao S3, apenas para fins da construção do projeto.\n",
        "\n",
        "> Para facilitar o processo, o Bot está presente exclusivamente para um grupo teste especifico, mas poderia ser aplicado em mais grupos com uma adaptação."
      ],
      "metadata": {
        "id": "yR3HVb_37YIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### **1\\.2. Sistema analítico**"
      ],
      "metadata": {
        "id": "cBGrbngl6v3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Caiombr/ebac-pipeline/blob/main/images-notebook/ETL.jpg?raw=true\" width=250/>"
      ],
      "metadata": {
        "id": "4PnbaKKrRTvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa etapa envolve o ETL (extração, transformação e carregamento) para que o dado coletado na etapa anterior, reservado em um bucket raw do `AWS S3` seja adaptado para um formato de melhor utilidade.\n",
        "\n",
        "No projeto, as mensagens de um único dia (sendo esse dia o dia anterior), persistidas na camada cru, serão compactas em um único arquivo, orientado a coluna e comprimido, que será persistido em uma camada enriquecida. Além disso, durante este processo, o dado também passará por etapas de data wrangling.\n",
        "\n",
        "O código Python utilizado no `AWS Lambda` para resgatar os dados das mensagens no `AWS S3` está nesse [link](https://github.com/Caiombr/ebac-pipeline/blob/main/ebac-caiombr-datalake-enriched.py). Também foi feito um código Python focado apenas para fazer o `MSCK REPAIR TABLE` no `AWS Athena` que está presente neste [link](https://github.com/Caiombr/ebac-pipeline/blob/main/ebac-caiombr-athena-msck.py);\n"
      ],
      "metadata": {
        "id": "WCtRzvxvD0Cu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/Caiombr/ebac-pipeline/main/images-notebook/stepfunctions_graph.png' width=250>\n",
        "\n",
        "Importante ressaltar que foi utilizado em conjunto o `AWS Step Functions` (código do JSON [aqui](https://github.com/Caiombr/ebac-pipeline/blob/main/ebac-stepfunctions.json) ) e o `AWS EventBrigde` como cronograma agendado de ativação do código Python e `AWS IAM` para permissões de acesso, extraindo as mensagens, fazendo a transformação diariamente para salvamento posterior no bucket enriched do `AWS S3` e rodando o `MSCK REPAIR TABLE`."
      ],
      "metadata": {
        "id": "IIkx0jT92kyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **2\\. Análise exploratória dos dados**"
      ],
      "metadata": {
        "id": "mFHiy8lVjXnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### **2.1. Coleta dos Dados**"
      ],
      "metadata": {
        "id": "o3eFuDeYF5ua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A primeira coisa a ser feita aqui envolve saber como que é o dado bruto JSON de cada interação no grupo do telegram que o Bot coleta. Para isso, foi utilizado o método *getUpdates* do Telegram, apenas para chegar as informações como exemplo. Com o projeto ativado, foi utilizado o método *webhook* que, quando conectado a API do AWS se torna uma forma eficaz de puxar os dados.\n",
        "\n"
      ],
      "metadata": {
        "id": "ixpHE54S8Xnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A estrutura base dele é a seguinte:"
      ],
      "metadata": {
        "id": "XqTuOdGZFzWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exemplo = {\"update_id\": 856310491,\n",
        "          \"message\":\n",
        "            {\"message_id\": 11,\n",
        "              \"from\": {\"id\": 1748419651, \"is_bot\": False, \"first_name\": \"Caio\", \"last_name\": \"Marques\"},\n",
        "              \"chat\": {\"id\": -1001850427822, \"title\": \"Analise de Dados\", \"type\": \"supergroup\"},\n",
        "              \"date\": 1690477846,\n",
        "              \"text\": \"hey jude\"}\n",
        "        }"
      ],
      "metadata": {
        "id": "kT307-Kr-m3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para possibilitar a utilização dos dados da forma que quisermos, ser o risco de perdemos nada, salvaremos as mensagens em seu formado mais cru, como apresentado acima. Assim, caso queiramos alterar a o processamento, a base de dados das mensagens se manterá inalterada."
      ],
      "metadata": {
        "id": "sYLd2zFvId7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considerando isso, apenas algumas dessas informações delas serão utilizadas neste projeto:\n",
        "\n",
        "\n",
        "*   message_id: O número ordenal das mensagens;\n",
        "*   user_id: ID do usuário da mensagem;\n",
        "*   user_is_bot: Booleano para verificar se o usuário é bot;\n",
        "*   user_first_name: Primeiro nome do usuário;\n",
        "*   chat_type: Tipo do chat (padrão é o supergroup);\n",
        "*   date: Número indicativo da hora e data do envio;\n",
        "*   data_type: Qual é o tipo do dado (texto, audio, imagem, etc.)\n",
        "*   text: Qual a mensagem de texto enviada (em caso de texto);\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8G4WYPu1BPpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ainda nessa etapa, os dados serão salvos em um bucket do `AWS S3`e particionados por data de envio. Isso facilita tando o processamento com velocidade, economia no `AWS Athena` e acesso ao armazenamento."
      ],
      "metadata": {
        "id": "mqXUCdE1KG0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com esses dados salvos, podemos seguir para a próxima etapa."
      ],
      "metadata": {
        "id": "TSNnNAn6JiMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### **2.2. Limpeza e transformação**"
      ],
      "metadata": {
        "id": "DI9d5tjrGLJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O foco aqui é só tratar essas mensagens que já estão no `AWS S3` para que elas possam serem transformadas em um formato utilizável no `AWS Athena`. Para isso, foi feito um código que recupera apenas as informações desejadas.\n",
        "\n"
      ],
      "metadata": {
        "id": "71KliOEpDfT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa é a função de transformação dentro do `AWS Lambda` no ebac-caiombr-datalake-enriched:"
      ],
      "metadata": {
        "id": "GUihaT1XERQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "def parse_data(data: dict) -> dict:\n",
        "\n",
        "    # O datetime converte a data presente no arquivo para um valor utilizável\n",
        "    date = datetime.now().strftime('%Y-%m-%d')\n",
        "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    parsed_data = dict()\n",
        "\n",
        "    for key, value in data.items():\n",
        "\n",
        "        if key == 'from':\n",
        "            for k, v in data[key].items():\n",
        "                if k in ['id', 'is_bot', 'first_name']:\n",
        "                    parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
        "\n",
        "        elif key == 'chat':\n",
        "            for k, v in data[key].items():\n",
        "                if k in ['id', 'type']:\n",
        "                    parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n",
        "\n",
        "        elif key in ['message_id', 'date']:\n",
        "            parsed_data[key] = [value]\n",
        "\n",
        "        elif key == 'text':\n",
        "            parsed_data['data_type'] = [key]\n",
        "            parsed_data[key] = [value]\n",
        "\n",
        "        elif key in ['voice', 'photo', 'video', 'new_chat_participant']:\n",
        "            parsed_data['data_type'] = [key]\n",
        "\n",
        "  # Verifica se a chave 'data_type' não foi adicionada no loop e define o valor padrão\n",
        "    if 'data_type' not in parsed_data:\n",
        "        parsed_data['data_type'] = ['unknown']\n",
        "\n",
        "    if not 'text' in parsed_data.keys():\n",
        "        parsed_data['text'] = ['sem mensagem']\n",
        "\n",
        "    return parsed_data"
      ],
      "metadata": {
        "id": "BQw35GjgDsDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chamando a função para o exemplo do 2.1. e fazendo o print, obtemos o seguinte resultado:"
      ],
      "metadata": {
        "id": "3csnj_1xHSTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_data = parse_data(data=exemplo[\"message\"])\n",
        "\n",
        "for key, value in parsed_data.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHlylsqfFBgQ",
        "outputId": "a2426d81-a473-46c1-bf92-1bd29301eb85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message_id: [11]\n",
            "user_id: [1748419651]\n",
            "user_is_bot: [False]\n",
            "user_first_name: ['Caio']\n",
            "chat_id: [-1001850427822]\n",
            "chat_type: ['supergroup']\n",
            "date: [1690477846]\n",
            "data_type: ['text']\n",
            "text: ['hey jude']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como a ideia desse projeto é trabalhar com a tabulação no SQL, a conversão será feita em parquet para particionamento e economia no gasto de dados no `AWS Athena`."
      ],
      "metadata": {
        "id": "ITgrzjuNQU7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "table = None\n",
        "\n",
        "iter_table = pa.Table.from_pydict(mapping=parsed_data)\n",
        "\n",
        "if table:\n",
        "\n",
        "  table = pa.concat_tables([table, iter_table])\n",
        "\n",
        "else:\n",
        "\n",
        "    table = iter_table\n",
        "    iter_table = None"
      ],
      "metadata": {
        "id": "UnimSrujQ67D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Lembrando que os detalhes de todo o procedimento do código em relação as aplicações da AWS estão presentes nos links da seção 1.2."
      ],
      "metadata": {
        "id": "ygoxHh21RQ8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, podemos seguir para a próxima etapa."
      ],
      "metadata": {
        "id": "-NDkuyI3Rf4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3. Visualização**"
      ],
      "metadata": {
        "id": "EAQeRPIiGL4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O primeiro passo é criar a tabela que terão os dados importados. O comando de criação usado, considerando as partições em `context_date`:"
      ],
      "metadata": {
        "id": "GC2Js2rRR60s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` sql\n",
        "CREATE EXTERNAL TABLE `telegram`(\n",
        "  `message_id` bigint,\n",
        "  `user_id` bigint,\n",
        "  `user_is_bot` boolean,\n",
        "  `user_first_name` string,\n",
        "  `chat_id` bigint,\n",
        "  `chat_type` string,\n",
        "  `data_type` string,\n",
        "  `text` string,\n",
        "  `date` bigint)\n",
        "PARTITIONED BY (\n",
        "  `context_date` date)\n",
        "ROW FORMAT SERDE\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
        "STORED AS INPUTFORMAT\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'\n",
        "OUTPUTFORMAT\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\n",
        "LOCATION\n",
        "  's3://ebac-caiombr-datalake-enriched/telegram/'\n",
        "```"
      ],
      "metadata": {
        "id": "TfkBgLTtSmdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código gerado no `AWS Athena` fará o carregamento das partições automaticamente todos os dias. Mas, para exemplificar:"
      ],
      "metadata": {
        "id": "kmyCKsdjTpKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` sql\n",
        "MSCK REPAIR TABLE `default`.`telegram`;\n",
        "```\n",
        "\n",
        "``` sql\n",
        "SELECT * FROM \"default\".\"telegram\" limit 10;;\n",
        "```"
      ],
      "metadata": {
        "id": "oSjXkUw3TNbn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sendo assim, temos a tabela a seguir de resultado:"
      ],
      "metadata": {
        "id": "KLHiNgydT32e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/Caiombr/ebac-pipeline/main/tabelas/select_all.jpg\" width=1000>\n"
      ],
      "metadata": {
        "id": "Xpue3uTlU0LM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos fazer mais consultas alias, como por exemplo:"
      ],
      "metadata": {
        "id": "4qm6V9eJU3ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Quantidade de mensagens por dia."
      ],
      "metadata": {
        "id": "N_mccjU3VRCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```sql\n",
        "SELECT\n",
        "  context_date,\n",
        "  count(1) AS \"message_amount\"\n",
        "FROM \"telegram\"\n",
        "GROUP BY context_date\n",
        "ORDER BY context_date DESC\n",
        "```"
      ],
      "metadata": {
        "id": "Q0229DjaVCDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/Caiombr/ebac-pipeline/main/tabelas/msgs_por_dia.jpg\" width=1000>\n"
      ],
      "metadata": {
        "id": "dCxOlKPAVCYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Qual o tipo de arquivo mais enviado pelos usuários."
      ],
      "metadata": {
        "id": "QiemvDNzVWPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```sql\n",
        "SELECT\n",
        "  data_type,\n",
        "  count(1) AS \"message_amount\"\n",
        "FROM \"telegram\"\n",
        "GROUP BY data_type\n",
        "ORDER BY message_amount DESC\n",
        "```"
      ],
      "metadata": {
        "id": "VeLtjyJBVUCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/Caiombr/ebac-pipeline/main/tabelas/data_type.jpg\" width=1000>\n"
      ],
      "metadata": {
        "id": "XV28RWEMWUn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Quantas mensagens cada usuário enviou."
      ],
      "metadata": {
        "id": "Zy9gBMyvWsXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```sql\n",
        "SELECT\n",
        "  user_first_name,\n",
        "  count(1) AS \"message_amount\"\n",
        "FROM \"telegram\"\n",
        "GROUP BY user_first_name\n",
        "ORDER BY message_amount DESC\n",
        "```"
      ],
      "metadata": {
        "id": "Mc1eoi9MW59p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/Caiombr/ebac-pipeline/main/tabelas/msgs_por_pessoa.jpg\" width=1000>\n"
      ],
      "metadata": {
        "id": "pU0uDv68XM6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Média do tamanho das mensagens por usuário por dia."
      ],
      "metadata": {
        "id": "kqc3Bs-QjLzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```sql\n",
        "SELECT\n",
        "  user_id,\n",
        "  user_first_name,\n",
        "  context_date,\n",
        "  CAST(AVG(length(text)) AS INT) AS \"average_message_length\"\n",
        "FROM \"telegram\"\n",
        "GROUP BY\n",
        "  user_id,\n",
        "  user_first_name,\n",
        "  context_date\n",
        "ORDER BY context_date DESC\n",
        "```"
      ],
      "metadata": {
        "id": "xG_k8zpAi_5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/Caiombr/ebac-pipeline/main/tabelas/avg_msg_dia_user.jpg\" width=1000>\n"
      ],
      "metadata": {
        "id": "UAfqJ9M3i_bm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Quantidade de mensagens por hora por dia da semana e por mês."
      ],
      "metadata": {
        "id": "BpcaltKJmUYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```sql\n",
        "WITH\n",
        "parsed_date_cte AS (\n",
        "    SELECT\n",
        "        *,\n",
        "        CAST(date_format(from_unixtime(\"date\"),'%Y-%m-%d %H:%i:%s') AS timestamp) AS parsed_date\n",
        "    FROM \"telegram\"\n",
        "),\n",
        "hour_week_cte AS (\n",
        "    SELECT\n",
        "        *,\n",
        "        EXTRACT(hour FROM parsed_date) AS parsed_date_hour,\n",
        "        EXTRACT(dow FROM parsed_date) AS parsed_date_weekday,\n",
        "        EXTRACT(month FROM parsed_date) AS parsed_date_month\n",
        "    FROM parsed_date_cte\n",
        ")\n",
        "SELECT\n",
        "    parsed_date_hour,\n",
        "    parsed_date_weekday,\n",
        "    parsed_date_month,\n",
        "    count(1) AS \"message_amount\"\n",
        "FROM hour_week_cte\n",
        "GROUP BY\n",
        "    parsed_date_hour,\n",
        "    parsed_date_weekday,\n",
        "    parsed_date_month\n",
        "ORDER BY\n",
        "    parsed_date_month,\n",
        "    parsed_date_weekday\n",
        "```"
      ],
      "metadata": {
        "id": "NeqjZVsWmUsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/Caiombr/ebac-pipeline/main/tabelas/hour_week_month.jpg\" width=1000>\n"
      ],
      "metadata": {
        "id": "SgWysQeZmVxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **3\\. Resultado**"
      ],
      "metadata": {
        "id": "Tt0ztFpzjPfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O primeiro resultado aparente:"
      ],
      "metadata": {
        "id": "AuArXi1DprHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Todas as mensagens no grupo do Telegram foram devidamente importadas, salvas em seu arquivo original, transformadas para um formato melhor para análise e tabelados.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3hcAypLTpCsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porém, em relação aos dados apresentados, podemos trazer algumas conclusões:"
      ],
      "metadata": {
        "id": "6ZcDivSOmEaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   O tipo de mensagem mais enviado até então é o de texto;\n",
        "*   O Caio é o usuário mais ativo no grupo atualmente, com 10 mensagens enviadas;\n",
        "*   As mensagens enviadas durante os dias se mantém muito próximo a média geral;\n",
        "*   O peso das mensagens também não é muito grande;\n",
        "*   O mês que foram enviadas as mensagens foi em Julho."
      ],
      "metadata": {
        "id": "U4xzoOjipqSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É possivel encontrar ainda mais informações ao passar do tempo e da constante de conversas sendo feitas no grupo. Como é apenas um projeto, serve como exemplo do que pode ser feito de fato."
      ],
      "metadata": {
        "id": "Cww-W4kPqv2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **4\\. Contato**"
      ],
      "metadata": {
        "id": "0FlRP1sFrIQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   LinkedIn: https://www.linkedin.com/in/caiombr/\n",
        "*   GitHub do projeto: https://github.com/Caiombr/ebac-pipeline\n",
        "*   Email: caiombr@gmail.com\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CNOVYWNBrLW4"
      }
    }
  ]
}